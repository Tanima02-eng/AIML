{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"Hello there, how are you? Weather is awesome....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\"Hello Mr. Raja, how are you? Weather is aweso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"Hello Mr. Raja, how are you. Weather is bad. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"NLP is great technique. It is nice to learn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"AI is making difference in this world now.  I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  \"Hello there, how are you? Weather is awesome....\n",
       "1  \"Hello Mr. Raja, how are you? Weather is aweso...\n",
       "2  \"Hello Mr. Raja, how are you. Weather is bad. ...\n",
       "3  \"NLP is great technique. It is nice to learn t...\n",
       "4  \"AI is making difference in this world now.  I..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('NLP1.xlsm')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COL:  \"Hello there, how are you? Weather is awesome. Its raining here now.\"\n",
      "COL:  \"Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.\"\n",
      "COL:  \"Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\"\n",
      "COL:  \"NLP is great technique. It is nice to learn this technique.\"\n",
      "COL:  \"AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.\"\n"
     ]
    }
   ],
   "source": [
    "tokens_list=[]\n",
    "for col in df['Comment']:\n",
    "    print('COL: ',col)\n",
    "    token=nltk.word_tokenize(col)\n",
    "    tokens_list.append(token)\n",
    "\n",
    "df2=pd.DataFrame({'tokens':tokens_list})\n",
    "    \n",
    "df2.head()\n",
    "final_df=pd.concat([df.reset_index(drop=True), df2.reset_index(drop=True)], axis=1)\n",
    "final_df\n",
    "\n",
    "final_df.to_excel('out.xlsm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S ``/``)\n",
      "(S Hello/NN)\n",
      "(S there/RB)\n",
      "(S ,/,)\n",
      "(S how/WRB)\n",
      "(S are/VBP)\n",
      "(S you/PRP)\n",
      "(S ?/.)\n",
      "(S Weather/NN)\n",
      "(S is/VBZ)\n",
      "(S awesome/NN)\n",
      "(S ./.)\n",
      "(S Its/PRP$)\n",
      "(S raining/VBG)\n",
      "(S here/RB)\n",
      "(S now/RB)\n",
      "(S ./.)\n",
      "(S ''/'')\n",
      "(S ``/``)\n",
      "(S Hello/NN)\n",
      "(S (Chunk Mr/NNP) ./.)\n",
      "(S Raja/NN)\n",
      "(S ,/,)\n",
      "(S how/WRB)\n",
      "(S are/VBP)\n",
      "(S you/PRP)\n",
      "(S ?/.)\n",
      "(S Weather/NN)\n",
      "(S is/VBZ)\n",
      "(S awesome/NN)\n",
      "(S ./.)\n",
      "(S Its/PRP$)\n",
      "(S raining/VBG)\n",
      "(S here/RB)\n",
      "(S now/RB)\n",
      "(S ./.)\n",
      "(S ''/'')\n",
      "(S ``/``)\n",
      "(S Hello/NN)\n",
      "(S (Chunk Mr/NNP) ./.)\n",
      "(S Raja/NN)\n",
      "(S ,/,)\n",
      "(S how/WRB)\n",
      "(S are/VBP)\n",
      "(S you/PRP)\n",
      "(S ./.)\n",
      "(S Weather/NN)\n",
      "(S is/VBZ)\n",
      "(S bad/JJ)\n",
      "(S ./.)\n",
      "(S Its/PRP$)\n",
      "(S heavily/RB)\n",
      "(S raining/VBG)\n",
      "(S here/RB)\n",
      "(S now/RB)\n",
      "(S ./.)\n",
      "(S ''/'')\n",
      "(S ``/``)\n",
      "(S NLP/NN)\n",
      "(S is/VBZ)\n",
      "(S great/JJ)\n",
      "(S technique/NN)\n",
      "(S ./.)\n",
      "(S It/PRP)\n",
      "(S is/VBZ)\n",
      "(S nice/JJ)\n",
      "(S to/TO)\n",
      "(S learn/NN)\n",
      "(S this/DT)\n",
      "(S technique/NN)\n",
      "(S ./.)\n",
      "(S ''/'')\n",
      "(S ``/``)\n",
      "(S AI/NN)\n",
      "(S is/VBZ)\n",
      "(S making/VBG)\n",
      "(S difference/NN)\n",
      "(S in/IN)\n",
      "(S this/DT)\n",
      "(S world/NN)\n",
      "(S now/RB)\n",
      "(S ./.)\n",
      "(S It/PRP)\n",
      "(S would/MD)\n",
      "(S be/VB)\n",
      "(S helpful/NN)\n",
      "(S for/IN)\n",
      "(S betterment/NN)\n",
      "(S of/IN)\n",
      "(S human/NN)\n",
      "(S life/NN)\n",
      "(S ./.)\n",
      "(S We/PRP)\n",
      "(S need/NN)\n",
      "(S to/TO)\n",
      "(S make/VB)\n",
      "(S advantage/NN)\n",
      "(S of/IN)\n",
      "(S that/IN)\n",
      "(S ./.)\n",
      "(S ''/'')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "       for tokens in tokens_list:\n",
    "         for i in tokens:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            print(chunked)\n",
    "            \n",
    "#             chunked.draw()     \n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('Hello', 'NNP'), ('there', 'RB'), (',', ','), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('?', '.'), ('Weather', \"''\"), ('is', 'VBZ'), ('awesome', 'JJ'), ('.', '.'), ('Its', 'PRP$'), ('raining', 'VBG'), ('here', 'RB'), ('now', 'RB'), ('.', '.'), (\"''\", \"''\")]\n",
      "(S\n",
      "  ``/``\n",
      "  Hello/NNP\n",
      "  there/RB\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ?/.\n",
      "  Weather/''\n",
      "  is/VBZ\n",
      "  awesome/JJ\n",
      "  ./.\n",
      "  Its/PRP$\n",
      "  raining/VBG\n",
      "  here/RB\n",
      "  now/RB\n",
      "  ./.\n",
      "  ''/'')\n",
      "[('``', '``'), ('Hello', 'NNP'), ('Mr.', 'NNP'), ('Raja', 'NNP'), (',', ','), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('?', '.'), ('Weather', \"''\"), ('is', 'VBZ'), ('awesome', 'JJ'), ('.', '.'), ('Its', 'PRP$'), ('raining', 'VBG'), ('here', 'RB'), ('now', 'RB'), ('.', '.'), (\"''\", \"''\")]\n",
      "(S\n",
      "  ``/``\n",
      "  Hello/NNP\n",
      "  Mr./NNP\n",
      "  Raja/NNP\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ?/.\n",
      "  Weather/''\n",
      "  is/VBZ\n",
      "  awesome/JJ\n",
      "  ./.\n",
      "  Its/PRP$\n",
      "  raining/VBG\n",
      "  here/RB\n",
      "  now/RB\n",
      "  ./.\n",
      "  ''/'')\n",
      "[('``', '``'), ('Hello', 'NNP'), ('Mr.', 'NNP'), ('Raja', 'NNP'), (',', ','), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP'), ('.', '.'), ('Weather', 'CC'), ('is', 'VBZ'), ('bad', 'JJ'), ('.', '.'), ('Its', 'PRP$'), ('heavily', 'RB'), ('raining', 'VBG'), ('here', 'RB'), ('now', 'RB'), ('.', '.'), (\"''\", \"''\")]\n",
      "(S\n",
      "  ``/``\n",
      "  Hello/NNP\n",
      "  Mr./NNP\n",
      "  Raja/NNP\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ./.\n",
      "  Weather/CC\n",
      "  is/VBZ\n",
      "  bad/JJ\n",
      "  ./.\n",
      "  Its/PRP$\n",
      "  heavily/RB\n",
      "  raining/VBG\n",
      "  here/RB\n",
      "  now/RB\n",
      "  ./.\n",
      "  ''/'')\n",
      "[('``', '``'), ('NLP', 'NNP'), ('is', 'VBZ'), ('great', 'JJ'), ('technique', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('nice', 'JJ'), ('to', 'TO'), ('learn', 'VB'), ('this', 'DT'), ('technique', 'NN'), ('.', '.'), (\"''\", \"''\")]\n",
      "(S\n",
      "  ``/``\n",
      "  NLP/NNP\n",
      "  is/VBZ\n",
      "  (NP great/JJ technique/NN)\n",
      "  ./.\n",
      "  It/PRP\n",
      "  is/VBZ\n",
      "  nice/JJ\n",
      "  to/TO\n",
      "  learn/VB\n",
      "  (NP this/DT technique/NN)\n",
      "  ./.\n",
      "  ''/'')\n",
      "[('``', '``'), ('AI', 'NNP'), ('is', 'VBZ'), ('making', 'VBG'), ('difference', 'NN'), ('in', 'IN'), ('this', 'DT'), ('world', 'NN'), ('now', 'RB'), ('.', '.'), ('It', 'PRP'), ('would', 'MD'), ('be', 'VB'), ('helpful', 'JJ'), ('for', 'IN'), ('betterment', 'NN'), ('of', 'IN'), ('human', 'JJ'), ('life', 'NN'), ('.', '.'), ('We', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('make', 'VB'), ('advantage', 'NN'), ('of', 'IN'), ('that', 'DT'), ('.', '.'), (\"''\", \"''\")]\n",
      "(S\n",
      "  ``/``\n",
      "  AI/NNP\n",
      "  is/VBZ\n",
      "  making/VBG\n",
      "  (NP difference/NN)\n",
      "  in/IN\n",
      "  (NP this/DT world/NN)\n",
      "  now/RB\n",
      "  ./.\n",
      "  It/PRP\n",
      "  would/MD\n",
      "  be/VB\n",
      "  helpful/JJ\n",
      "  for/IN\n",
      "  (NP betterment/NN)\n",
      "  of/IN\n",
      "  (NP human/JJ life/NN)\n",
      "  ./.\n",
      "  We/PRP\n",
      "  need/VBP\n",
      "  to/TO\n",
      "  make/VB\n",
      "  (NP advantage/NN)\n",
      "  of/IN\n",
      "  that/DT\n",
      "  ./.\n",
      "  ''/'')\n"
     ]
    }
   ],
   "source": [
    "list_tag=[]\n",
    "for tokens in tokens_list:\n",
    "    ptag=nltk.pos_tag(tokens)\n",
    "    print (ptag)\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "    cp  =nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(ptag)\n",
    "    print(result)\n",
    "    result.draw()\n",
    "    list_tag.append(ptag)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
